---
img: "106.jpg"
---

# **February 3rd, Stammtisch #106**

47 ppl



**Simon**



Shows software his team works on to be able to control a mouse pointer and mouse buttons with the movements of a hand wearing a smart watch. It uses the accelerometers and gyroscopes on the watch to detect subtle vibrations and rotations.

[https://playground.port6.io/watch-raycast-keyboard/](https://playground.port6.io/watch-raycast-keyboard/)



[https://github.com/port6io](https://github.com/port6io)

[https://www.port6.io/](https://www.port6.io/)



Follow Simon for updates: [https://twitter.com/fruebis](https://twitter.com/fruebis)



**Louis**

Embeddings (openai)

Machine learning used to find matching relationships (similar distance) between pairs of words (like king-queen -> boy-girl).

Open source API [https://github.com/another-ai/embedbase](https://github.com/another-ai/embedbase)

OpenAI's text embeddings: [https://platform.openai.com/docs/guides/embeddings](https://platform.openai.com/docs/guides/embeddings)

He uses it as part of Obsidian note-taking app.



**VJFader James**

[https://vjfader.com/](https://vjfader.com/)

Quick path on his usage of tools. He mixes video live. Initially MaxMSP 20 years ago. Was bought by Ableton, who don't develop Jitter much anymore. He crated AVMixer.

Then he used Processing. Later transitioned to Unity. The switch from Java (Processing) to C-Sharp (Unity) was easy. Also tried Touch Designer. Later he switched to Unreal engine, specially the Niagara particle system. He really got into it.



**Gabor**

Performs live-coding with his software producing spectrograms, originally developed for transferring data as sound from a watch to a computer which listens and decodes the tones.

[https://jealousmarkup.xyz/off/chirpy/rx/]([]https://jealousmarkup.xyz/off/chirpy/rx/[])



**== Announcements ==**

* Alma: organizing a Creative Coding summer camp. Looking for help with finding funding.
* A flat needed!
* Josh: looking for dancers to film for doing generative dance.
* Abe: Holon Space laser show [https://www.holon.berlin/](https://www.holon.berlin/) LOOM


**== Break ==**



**Kazik**

Was working on a sound reactive shader on ShaderToy, with music from Julie. She shared with Kazik a dream involving a train station and piano music, which she later composed, and Kazik used it as part of this work.

Spectral Zuconi color model

[https://www.alanzucconi.com/2017/07/15/improving-the-rainbow-2/](https://www.alanzucconi.com/2017/07/15/improving-the-rainbow-2/)



[https://www.shadertoy.com/view/dllSWj](https://www.shadertoy.com/view/dllSWj)



**Alma**

Inspired by impresionism. She's been capturing landscapes with photogrammetry and uses Touch Designer. The musician provides some tracks she will play in advance, which is much more reliable than real-time analysis. She's been getting into GLSL to apply effects to point clouds.



**Walter**

He's been learning Touch Designer and created a patch that reacts to music and MIDI input. He only had one MIDI controller with 8 pads, 8 knobs and keys, so he hacked it to change the meaning of the knobs by pressing keys. It can save presets when he finds nice combinations, and recall the presets with the pads



**Josh**

[https://github.com/lucidbeaming/vid2midi](https://github.com/lucidbeaming/vid2midi), a sonifier. Python library. Takes a video file, and setting some command line switches, controls the produced midi information. Later you can use the midi tracks and attach sounds or synthesizers to it. 

This is one of the results.

[https://www.youtube.com/watch?v=WEJWphCaq9Y](https://www.youtube.com/watch?v=WEJWphCaq9Y)

