---
img: "117.webp"
---

# **January 5th, Stammtisch #117**

~41 ppl



== introductions ==



**Alex**

Alex has been focusing on microcontrollers (micro python) and through his projects, he has been also learning modelling and 3D printing.

Alex presents a project using ESP32 controller + battery pack + LEDS, for Biomodulation / biohacking on the shape of a pair of goggles for Binaural (2 sound frequencies beating between left and right ears altering your brainwaves)

with 2 red LEDs blinking at 10hz he is trying to induce a mindset of meditation / psychedelic state.



[https://instagram.com/alexkaos](https://instagram.com/alexkaos)



**Nikita**

He worked on a commercial project for a company making shoes. Involving photogrammetry, AR and mobiles. Concepts: "AR try-on" to see the shoes on your feet, virtual mirror, 3D interactive animations, widgets to customize shoes, pixel streaming (3D rendering happens on a remote server on a powerful computer, often involves waiting in a queue), virtual showrooms. They decided to use a 3D display and photogrammetry. With cross-polarization the quality of the scans can be improved. The project continues...



**Pascal**

[https://pascal.cc/blog/artificial-psychometrics](https://pascal.cc/blog/artificial-psychometrics)

He's been working for 6 months. Show screens from chats with Microsoft's AI bot sydney which reacted in weird ways. The AI bot got frustrated and wanted to end the conversation. After he saw the table showing all the tests Chat GPT could pass, he was curious about such a table regarding to psychological traits and behavior. He wondered what would happen if you apply psychometrics: questionnaires to analize people. He applied with a friend for a grant in the Netherlands to develop such a project. His research is coming to an end now. He used the PID-5, BigFive questionnaires.

He called his project Interlink, inspired by Blade Runner.

[https://github.com/pskl/interlink](https://github.com/pskl/interlink)

[http://pascal.cc/interlink/](http://pascal.cc/interlink/)



== announcements ==



- Nikita: Motion Lab AV Jam, January 26th. Apply as visual artist / musician. 

- New meetup: "open source machine learning". January 20th.[https://www.meetup.com/open-source-machine-learning-association/events/298351557/](https://www.meetup.com/open-source-machine-learning-association/events/298351557/)

- Three available desks in a studio in Neukölln. 166€ [https://www.kleinanzeigen.de/s-anzeige/platz-in-gemeinschafts-atelier-zur-miete-ab-1-1-2024/2633507429-277-3394](https://www.kleinanzeigen.de/s-anzeige/platz-in-gemeinschafts-atelier-zur-miete-ab-1-1-2024/2633507429-277-3394)



== break ==



**Meredith**

Creative technologist and artist. He worked on a project in Hamburg 3 months ago.

Using an AI tool during a walking tour, the group of audience can take photos with a smartphone and visualize a narrative through 5 generations in the future of a fictional creature. It enables an imaginative near-future vision of Hamburg, as it experiences a climate crisis.

The technoogy was created to support the story the performer wanted to tell.

The whole experience was around 30 mins with an intro and a 20 mins walk.

[https://www.creativecoding.city/goodbyehamburg](https://www.creativecoding.city/goodbyehamburg)

[https://www.youtube.com/watch?v=E1CrCwICe2s\&ab\_channel=FabiolaKuonen](https://www.youtube.com/watch?v=E1CrCwICe2s\&ab\_channel=FabiolaKuonen)



**Alex**

Online you can find many services to generate media using AI, but he wanted to know how to do this yourself. Ideally you need a powerful computer, but you could do with any. It will just take longer. He found ComfyUI in GitHub ([https://github.com/comfyanonymous/ComfyUI)](https://github.com/comfyanonymous/ComfyUI)) which you can run locally, even on the CPU. It opens a UI in a web browser.

Explains the basics of a neural network: an input which is a list of numbers (could represent letters, pixels), functions that transform input numbers into output numbers, and finally an output, which can again be words, pixels, sound...

He demos generating a simple image of the "red riding hood" based on a prompt.

There are many places online where one can download models, which are very big files full of weights.



[https://github.com/fractal-obsession/videoproc](https://github.com/fractal-obsession/videoproc)



Shows a video clip he generated that swings from original video to AI generated:

[https://www.instagram.com/fractal\_obsession/](https://www.instagram.com/fractal\_obsession/)



Reference: "Lost - Linkin Park" popular video using AI:

[https://www.youtube.com/watch?v=7NK\_JOkuSVY](https://www.youtube.com/watch?v=7NK\_JOkuSVY)

